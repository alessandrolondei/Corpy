{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = './Books/it/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = './texts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_files = glob.glob(books_path + '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./texts/sleep.txt', './texts/the_open_boat.txt']"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = []\n",
    "for bf in book_files:\n",
    "    with open(bf, 'r') as f:\n",
    "        books.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpy():\n",
    "\n",
    "    def __init__(self, books, **kwargs):\n",
    "        self.mode                = kwargs.get('mode',                'word'  )\n",
    "        self.lower               = kwargs.get('lower',               True    )\n",
    "        self.one_document        = kwargs.get('one_document',        False   )\n",
    "        self.threshold           = kwargs.get('threshold',           None    )\n",
    "        self.threshold_section   = kwargs.get('threshold_section', 'first' ) # 'first', 'all' or int\n",
    "        self.text_sections       = kwargs.get('text_sections',       (1,)    ) # tuple or list: (train, valid, test, ...)\n",
    "        self.text_sections_level = kwargs.get('text_sections_level', 'book'  ) # 'book' or 'item'\n",
    "        self.init_books_seq      = kwargs.get('init_books_seq',      'normal') # 'normal', 'random' or sequence list\n",
    "        self.punct               = kwargs.get('punct',                \"'.,!?«»:;()[]-\"   ) # list or string of punctuation to divide words\n",
    "        \n",
    "        \n",
    "        self.ind_books = np.arange(len(books))\n",
    "        if type(self.init_books_seq) == str:\n",
    "            if self.init_books_seq == 'normal':\n",
    "                pass\n",
    "            elif self.init_books_seq == 'random':\n",
    "                np.random.shuffle(self.ind_books)\n",
    "            else:\n",
    "                warnings.warn('Init_books_seq not recognised. Using \\'normal\\'', UserWarning)\n",
    "        elif type(self.init_books_seq) == list:\n",
    "            self.ind_books = self.init_books_seq\n",
    "        else:\n",
    "            raise ValueError('init_books_seq must be a string (\\'normal\\' or \\'random\\') or a list of indexes')\n",
    "            \n",
    "                \n",
    "        if self.one_document:\n",
    "            string = ''\n",
    "            for b in books:\n",
    "                string += b + ' '\n",
    "            self.books = [string]\n",
    "            self.ind_books = [0]\n",
    "        else:\n",
    "            self.books = copy.deepcopy(books) # list of book strings\n",
    "        self.num_books = len(self.books)\n",
    "        \n",
    "        self.books_list_of_items = None # list of book lists containing the single items\n",
    "        self.books_encoding = None # list of book encodings\n",
    "        self.items_count = None # dictionary with the number of items (word or char) occourrences\n",
    "        self.items_freq = None # dictionary with the frequency of items occourrences\n",
    "        self.ind2item = None # dictionary to translate one item encoding to item\n",
    "        self.item2ind = None # dictionary to translate an item to the associated encoding\n",
    "        self.num_items = None # number of different items\n",
    "        \n",
    "        self.book_ind  = [0] * len(self.text_sections)\n",
    "        self.chunk_ind = [0] * len(self.text_sections)\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "    def _build(self):\n",
    "        all_items = []\n",
    "        self.books_list_of_items = []\n",
    "        \n",
    "        # Reading the full text\n",
    "        for k in self.ind_books:\n",
    "            b = self.books[k]\n",
    "            if self.lower:\n",
    "                self.books[k] = self.books[k].lower()\n",
    "            if self.mode == 'word':\n",
    "                for p in self.punct:\n",
    "                    self.books[k] = self.books[k].replace(p, \" \"+p+\" \")\n",
    "                while self.books[k].find('  ') > -1:\n",
    "                    self.books[k] = self.books[k].replace('  ', ' ')\n",
    "                self.books[k] = self.books[k].strip()\n",
    "                self.books_list_of_items.append(self.books[k].split(' '))\n",
    "            elif self.mode == 'char':\n",
    "                self.books_list_of_items.append(list(self.books[k]))\n",
    "            #all_items += self.books_list_of_items[-1]\n",
    "        \n",
    "        # Building the sections\n",
    "        self._sections_building()\n",
    "        \n",
    "        # Calculating the items distribution\n",
    "        if type(self.threshold_section) == int:\n",
    "            for kb, b in enumerate(self.sections_book[self.threshold_section]):\n",
    "                #print(b)\n",
    "                fr, to = self.sections_text[self.threshold_section][kb]\n",
    "                all_items += self.books_list_of_items[b][fr:to]\n",
    "        elif type(self.threshold_section) == str:\n",
    "            if self.threshold_section == 'first':\n",
    "                for kb, b in enumerate(self.sections_book[0]):\n",
    "                    fr, to = self.sections_text[0][b]\n",
    "                    all_items += self.books_list_of_items[kb][fr:to]\n",
    "            elif self.threshold_section == 'all':\n",
    "                for b in self.books_list_of_items:\n",
    "                    all_items += b\n",
    "                \n",
    "        self.items_count = collections.Counter(all_items)\n",
    "        self.items_count = {k: v for k, v in sorted(self.items_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "        self.num_items = len(self.items_count)\n",
    "        tot_items = len(all_items)\n",
    "        self.items_freq = dict()\n",
    "        for k in self.items_count:\n",
    "            self.items_freq[k] = self.items_count[k] / tot_items\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Cutting the distribution\n",
    "        if self.threshold is not None:\n",
    "            if self.mode == 'char':\n",
    "                warnings.warn('Char mode. Threshold should not be used.', UserWarning)\n",
    "            key2remove = []\n",
    "            if self.threshold > 1:\n",
    "                self.threshold = int(self.threshold)\n",
    "                for k, (key, value) in enumerate(self.items_count.items()):\n",
    "                    if k >= self.threshold:\n",
    "                        key2remove.append(key)\n",
    "            elif self.threshold < 1. and self.threshold > 0.:\n",
    "                cumv = 0.0\n",
    "                for key, value in self.items_freq.items():\n",
    "                    cumv += value\n",
    "                    if cumv >= self.threshold:\n",
    "                        key2remove.append(key)\n",
    "            else:\n",
    "                raise ValueError('max_items must be positive!')\n",
    "            for key in key2remove:\n",
    "                del self.items_freq[key]\n",
    "                del self.items_count[key]\n",
    "            self.num_items = len(self.items_count)\n",
    "        \n",
    "        # Building the dictionaries for connecting items to code\n",
    "        self.ind2item = dict()\n",
    "        self.item2ind = dict()\n",
    "        for k, key in enumerate(self.items_count):\n",
    "            self.ind2item[k] = key\n",
    "            self.item2ind[key] = k\n",
    "        self.item2ind = collections.OrderedDict(sorted(self.item2ind.items()))\n",
    "        \n",
    "        # Updating the text after cutting distribution\n",
    "        self.books_encoding = []\n",
    "        for kb, b in enumerate(self.books_list_of_items):\n",
    "            self.books_encoding.append([])\n",
    "            for k, w in enumerate(b):\n",
    "                code = self.item2ind.get(w, None)\n",
    "                self.books_encoding[-1].append(code)\n",
    "                self.books_list_of_items[kb][k] = self.ind2item.get(code)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Removing the unnecessary data\n",
    "        del self.books\n",
    "        del self.num_items\n",
    "        del self.items_count\n",
    "        del self.items_freq\n",
    "    \n",
    "    def _sections_building(self):\n",
    "        ss_sum = 0.0\n",
    "        self.text_sections = list(self.text_sections)\n",
    "        for ss in self.text_sections:\n",
    "            ss_sum += ss\n",
    "        for k, ss in enumerate(self.text_sections):\n",
    "            self.text_sections[k] /= ss_sum\n",
    "        full_text_len = 0\n",
    "        for kb in range(len(self.books_list_of_items)):\n",
    "            full_text_len += len(self.books_list_of_items[kb])\n",
    "        number_of_items_per_section = []\n",
    "        for section_k, ts in enumerate(self.text_sections):\n",
    "            number_of_items_per_section.append(int(ts * full_text_len))\n",
    "        if sum(number_of_items_per_section) < full_text_len:\n",
    "            number_of_items_per_section[-1] += full_text_len - sum(number_of_items_per_section)\n",
    "        \n",
    "        self.sections_book = [[]]\n",
    "        self.sections_text = [[]]\n",
    "        \n",
    "        if self.text_sections_level == 'item':\n",
    "            book = 0\n",
    "            fr = 0\n",
    "\n",
    "            for section_k, nips in enumerate(number_of_items_per_section):\n",
    "                nips_rem = number_of_items_per_section[section_k]\n",
    "                while nips_rem > 0:\n",
    "                    if len(self.books_list_of_items[book][fr:]) <= nips_rem:\n",
    "                        self.sections_book[section_k].append(book)\n",
    "                        self.sections_text[section_k].append([fr,len(self.books_list_of_items[book])])\n",
    "                        nips_rem -= len(self.books_list_of_items[book]) - fr\n",
    "                        fr = 0\n",
    "                        book += 1\n",
    "                    else:\n",
    "                        self.sections_book[section_k].append(book)\n",
    "                        if nips_rem > len(self.books_list_of_items[book]) - fr:\n",
    "                            to = len(self.books_list_of_items[book])\n",
    "                            self.sections_text[section_k].append([fr, to])\n",
    "                            fr = 0\n",
    "                            book += 1\n",
    "                            nips_rem -= to - fr\n",
    "                        else:\n",
    "                            to = fr + nips_rem\n",
    "                            self.sections_text[section_k].append([fr, to])\n",
    "                            nips_rem -= to - fr\n",
    "                            fr = to                        \n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                        \n",
    "        elif self.text_sections_level == 'book':\n",
    "            section_k = 0\n",
    "            temp_len = 0\n",
    "            for kb, b in enumerate(self.books_list_of_items):\n",
    "                if len(b) + temp_len < number_of_items_per_section[section_k]:\n",
    "                    self.sections_book[section_k].append(kb)\n",
    "                    self.sections_text[section_k].append([0, len(b)])\n",
    "                    temp_len += len(b)\n",
    "                else:\n",
    "                    if (number_of_items_per_section[section_k] - temp_len) > int(len(b) * 0.75):\n",
    "                        self.sections_book[section_k].append(kb)\n",
    "                        self.sections_text[section_k].append([0, len(b)])\n",
    "                        section_k += 1\n",
    "                        temp_len = 0\n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                    else:\n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                            section_k += 1\n",
    "                            self.sections_book[section_k].append(kb)\n",
    "                            self.sections_text[section_k].append([0, len(b)])\n",
    "                            temp_len = len(b)\n",
    "            \n",
    "            for k, sb in enumerate(self.sections_book):\n",
    "                if sb == []:\n",
    "                    del self.sections_book[k]\n",
    "                    del self.sections_text[k]\n",
    "            \n",
    "            if len(self.sections_book) < len(self.text_sections):\n",
    "                wstr = 'Number of sections lower than requested: {}/{}'.format(len(self.sections_book), len(self.text_sections))\n",
    "                warnings.warn(wstr, UserWarning)\n",
    "        \n",
    "    \n",
    "    def reset_counter(self, section='all'):\n",
    "        if type(section) == int:\n",
    "            self.book_ind[section] = 0\n",
    "            self.chunk_ind[section] = 0\n",
    "        elif type(section) == str and section == 'all':\n",
    "            for s in range(len(self.sections_book)):\n",
    "                self.book_ind[s] = 0\n",
    "                self.chunk_ind[s] = 0\n",
    "    \n",
    "    def string2code(self, string):\n",
    "        code = []\n",
    "        string_list_of_items = []\n",
    "        if self.mode == 'word':\n",
    "            #self.punct = \"'.,!?«»:;()[]-\"\n",
    "            for p in self.punct:\n",
    "                string = string.replace(p, \" \"+p+\" \")\n",
    "            while string.find('  ') > -1:\n",
    "                string = string.replace('  ', ' ')\n",
    "            string = string.strip()\n",
    "            string_list_of_items = string.split(' ')\n",
    "        elif self.mode == 'char':\n",
    "            string_list_of_items = list(string)\n",
    "        for w in string_list_of_items:\n",
    "            code.append(self.item2ind.get(w))\n",
    "        return code\n",
    "    \n",
    "    def items2code(self, items):\n",
    "        code = []\n",
    "        for w in items:\n",
    "            code.append(self.item2ind.get(w))\n",
    "        return code\n",
    "    \n",
    "    def code2items(self, code):\n",
    "        items = []\n",
    "        for c in code:\n",
    "            items.append(self.ind2item.get(c))\n",
    "        return items\n",
    "    \n",
    "    def code2string(self, code):\n",
    "        string = ''\n",
    "        for c in code:\n",
    "            string += self.ind2item.get(c, 'UNK')\n",
    "            if self.mode == 'word':\n",
    "                string += ' '\n",
    "        string = string.strip()\n",
    "        return string\n",
    "    \n",
    "    def get_chunk(self, **kwargs):\n",
    "        book_sel     = kwargs.get('book_sel'      , -1        ) # book index relative to the chosen section\n",
    "        chunk_sel    = kwargs.get('chunk_sel'     , -1        ) # chunk starting index relative to the book in the section\n",
    "        chunk_len    = kwargs.get('chunk_len'     , 30        )\n",
    "        chunk_mode   = kwargs.get('chunk_mode'    , 'normal'  ) # 'normal', 'sequential', 'random'\n",
    "        padding      = kwargs.get('padding'       , 0         )\n",
    "        last_element = kwargs.get('last_element'  , True      )\n",
    "        output_mode  = kwargs.get('output_mode'   , 'code'    ) # 'code' list, 'item' list, 'string'\n",
    "        section      = kwargs.get('section'       , 0         ) # index (int) of the section or 'all'\n",
    "        unk          = kwargs.get('unk'           , 'max'     ) # In case of output_mode='code': \n",
    "                                                                #    'max': insert the code=max item\n",
    "                                                                #    'none': insert None\n",
    "                                                                # In case of output_mode='item' or 'string':\n",
    "                                                                #    insert the passed string\n",
    "        \n",
    "        if type(section) == int:\n",
    "            books = self.sections_book[section] # list of absolute index in the section\n",
    "        elif type(section) == str and section == 'all':\n",
    "            books = list(range(self.num_books))\n",
    "        texts = []\n",
    "        for kb, b in enumerate(books):\n",
    "            texts.append(self.sections_text[section][kb]) # list of couples [init,end] of each book in the section\n",
    "        num_books = len(books)        \n",
    "        \n",
    "        if chunk_mode == 'sequential':\n",
    "            book_sel_rel = self.book_ind[section]\n",
    "            book_sel_abs = books[book_sel_rel]\n",
    "            chunk_sel_abs = self.chunk_ind[section] + texts[book_sel_rel][0]\n",
    "        elif chunk_mode == 'random':\n",
    "            book_sel_rel = random.randint(0,len(books)-1)\n",
    "            book_sel_abs = books[book_sel_rel]\n",
    "            chunk_sel_abs = random.randint(texts[book_sel_rel][0], texts[book_sel_rel][1]-10)\n",
    "        elif chunk_mode == 'normal':\n",
    "            if book_sel == -1 or chunk_sel == -1:\n",
    "                raise ValueError('get_chunk: if sequential=False, book_sel and chunk_sel must be greater than -1')\n",
    "            else:\n",
    "                book_sel_rel = book_sel\n",
    "                book_sel_abs = books[book_sel_rel]\n",
    "                chunk_sel_abs = chunk_sel\n",
    "                if chunk_sel >= texts[book_sel_rel][1]:\n",
    "                    raise ValueError('get_chunk: chunk_sel is greater than the chosen section chunk')\n",
    "        \n",
    "        end_book = False\n",
    "    \n",
    "        if book_sel_abs < len(self.books_encoding):\n",
    "            if chunk_sel_abs < texts[book_sel_rel][1]:\n",
    "                fr = chunk_sel_abs\n",
    "                to = fr + chunk_len\n",
    "                if last_element:\n",
    "                    to += 1\n",
    "                if to > texts[book_sel_rel][1]:\n",
    "                    to = texts[book_sel_rel][1]\n",
    "                    end_book = True\n",
    "                if output_mode == 'code':\n",
    "                    output = self.books_encoding[book_sel_abs][fr:to]\n",
    "                    if unk == 'max':\n",
    "                        for k, o in enumerate(output):\n",
    "                            if o is None:\n",
    "                                output[k] = len(self.ind2item)\n",
    "                    elif unk == 'none':\n",
    "                        pass\n",
    "                elif output_mode == 'item':\n",
    "                    output = self.books_list_of_items[book_sel_abs][fr:to]\n",
    "                    for k, o in enumerate(output):\n",
    "                        if o is None:\n",
    "                            if self.mode == 'word':\n",
    "                                if unk=='max':\n",
    "                                    output[k] = 'UNK'\n",
    "                                elif unk=='none':\n",
    "                                    output[k] = None\n",
    "                                else:\n",
    "                                    output[k] = unk\n",
    "                elif output_mode == 'string':\n",
    "                    output = self.code2string(self.books_encoding[book_sel_abs][fr:to])\n",
    "            else:\n",
    "                raise ValueError('get_chunk: chunk_sel greater than book length')\n",
    "        else:\n",
    "            raise ValueError('get_chunk: book_sel greater than total books')\n",
    "            \n",
    "        if chunk_mode == 'sequential':\n",
    "            if end_book:\n",
    "                self.book_ind[section] += 1\n",
    "                if self.book_ind[section] >= len(books):\n",
    "                    self.book_ind[section] = 0\n",
    "                self.chunk_ind[section] = 0\n",
    "            else:\n",
    "                if padding < 1:\n",
    "                    self.chunk_ind[section] += chunk_len\n",
    "                else:\n",
    "                    self.chunk_ind[section] += padding\n",
    "                    if self.chunk_ind[section] >= len(texts[self.book_ind[section]]):\n",
    "                        self.chunk_ind[section] = 0\n",
    "                        self.book_ind[section] += 1\n",
    "                        if self.book_ind[section] >= len(books):\n",
    "                            self.book_ind[section] = 0\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-442-30cc7b008623>:230: UserWarning: Number of sections lower than requested: 1/3\n",
      "  warnings.warn(wstr, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpy(books, mode='word', text_sections=[80,15,5], text_sections_level='book', threshold_section=0, one_document=True)\n",
    "#len(corpus.ind2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[[[0, 27803]]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.sections_book)\n",
    "print(corpus.sections_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.reset_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['this',\n",
       "  'is',\n",
       "  'my',\n",
       "  'seventeenth',\n",
       "  'straight',\n",
       "  'day',\n",
       "  'without',\n",
       "  'sleep',\n",
       "  '.',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'not',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'insomnia',\n",
       "  '.',\n",
       "  'i',\n",
       "  'know',\n",
       "  'what',\n",
       "  'insomnia',\n",
       "  'is',\n",
       "  '.',\n",
       "  'i',\n",
       "  'had',\n",
       "  'something',\n",
       "  'like',\n",
       "  'it',\n",
       "  'in',\n",
       "  'college',\n",
       "  '-'],\n",
       " [0, 0, 0],\n",
       " [30, 0, 0])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_chunk(chunk_mode='sequential', section=0, output_mode='item'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"giovanni percolla aveva quarant ' anni , e viveva da dieci anni in compagnia di tre sorelle , la più giovane delle quali diceva di esser vedova di guerra . non\",\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 30, 0, 0, 0])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_chunk(chunk_mode='normal', book_sel=1, chunk_sel=0, section=0, output_mode='string'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"più la barba lunga e non c ' era motivo che lei fingesse . stava in piedi sullo sgabello , caricava il fonografo , lenta , e quando l ' afferrai\",\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 30, 0, 0, 0])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_chunk(chunk_mode='random', section=0, output_mode='string'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.book_ind[1] = 12\n",
    "corpus.chunk_ind[1] = 355000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 12, 0, 0, 0], [0, 355000, 0, 0, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84283"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(books, mode='word', text_sections=[0.8,0.4,0.1], text_sections_level='book', threshold_section='first')\n",
    "len(corpus.ind2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] [[0, 66132], [0, 53520], [0, 133440], [0, 53760], [0, 79664], [0, 167845], [0, 36894], [0, 82351], [0, 99026], [0, 91992], [0, 50881], [0, 87343], [0, 29091], [0, 93209], [0, 61281], [0, 71492], [0, 203649], [0, 90610], [0, 88864], [0, 57092], [0, 59443], [0, 113124], [0, 171281], [0, 84153], [0, 127016], [0, 49007], [0, 125716], [0, 24729], [0, 605402], [0, 201008], [0, 90625]]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'book_limits' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-82ebf0863fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sequential'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-9b25c805b263>\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbook_sel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooks_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m#if chunk_sel < len(self.books_encoding[book_sel]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mchunk_sel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbook_limits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_sel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'book_limits' referenced before assignment"
     ]
    }
   ],
   "source": [
    "corpus.get_chunk(chunk_mode='sequential', section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 66132]\n",
      "1 [0, 53520]\n",
      "2 [0, 133440]\n",
      "3 [0, 53760]\n",
      "4 [0, 79664]\n",
      "5 [0, 167845]\n",
      "6 [0, 36894]\n",
      "7 [0, 82351]\n",
      "8 [0, 99026]\n",
      "9 [0, 91992]\n",
      "10 [0, 50881]\n",
      "11 [0, 87343]\n",
      "12 [0, 29091]\n",
      "13 [0, 93209]\n",
      "14 [0, 61281]\n",
      "15 [0, 71492]\n",
      "16 [0, 203649]\n",
      "17 [0, 90610]\n",
      "18 [0, 88864]\n",
      "19 [0, 57092]\n",
      "20 [0, 59443]\n",
      "21 [0, 113124]\n",
      "22 [0, 171281]\n",
      "23 [0, 84153]\n",
      "24 [0, 127016]\n",
      "25 [0, 49007]\n",
      "26 [0, 125716]\n",
      "27 [0, 24729]\n",
      "28 [0, 605402]\n",
      "29 [0, 201008]\n",
      "30 [0, 90625]\n",
      "31 [0, 195302]\n",
      "32 [0, 114219]\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(corpus.sections_book[0])):\n",
    "    print(corpus.sections_book[0][k], corpus.sections_text[0][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112661, 112661)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(books, mode='word', one_document=False)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63741, 63741)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(books, mode='word', one_document=False, threshold=.99)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7412"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(books, mode='word', threshold=.9, unk_coding='max')\n",
    "len(corpus.item2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = corpus.books_encoding[0]\n",
    "#corpus.code2items(code)\n",
    "#corpus.code2string(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-7b6fd9879fa6>:62: UserWarning: Char mode. Threshold should not be used.\n",
      "  warnings.warn('Char mode. Threshold should not be used.', UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(53, 53)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(books, mode='char', one_document=False, threshold=1000)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode: char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i pare proprio l'albergo che fa\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus.reset_counter()\n",
    "chunk = corpus.get_chunk(chunk_mode='sequential',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='string',\n",
    "                         last_element=True,\n",
    "                         padding = 0)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dopo era sotto di me come un u'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='random',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='string',\n",
    "                         last_element=True)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode: word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', threshold=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"« figliuolo » . « papà » . « questo mi pare proprio l ' albergo che fa per noi » . « te lo stavo per dire » . «\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='sequential',\n",
    "                         chunk_len=30,\n",
    "                         #output_mode='item',\n",
    "                         output_mode='string',\n",
    "                         last_element=True,\n",
    "                         unk='none'\n",
    "                         )\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,\n",
       " ['.',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'aveva',\n",
       "  'preso',\n",
       "  'in',\n",
       "  'questo',\n",
       "  'modo',\n",
       "  ',',\n",
       "  'ormai',\n",
       "  ',',\n",
       "  'e',\n",
       "  'non',\n",
       "  'c',\n",
       "  \"'\",\n",
       "  'era',\n",
       "  'verso',\n",
       "  'di',\n",
       "  'UNK',\n",
       "  '!',\n",
       "  'una',\n",
       "  'ragazza',\n",
       "  ',',\n",
       "  'eleonora',\n",
       "  'UNK',\n",
       "  ',',\n",
       "  'cominciò',\n",
       "  'a',\n",
       "  'UNK',\n",
       "  '.',\n",
       "  'era'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='random',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='item',\n",
    "                         last_element=True)\n",
    "len(chunk), chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casual phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 1602, 7186, 221, 27, None]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = corpus.string2code('ci vediamo giovedì sera da Bernie')\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ci', 'vediamo', 'giovedì', 'sera', 'da', None]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.code2items(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ci vediamo giovedì sera da XXX'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.code2string(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 1602, 7186, 221, 27, None]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.items2code(['ci', 'vediamo', 'giovedì', 'sera', 'da', 'Bernie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
