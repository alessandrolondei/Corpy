{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = './Books/it/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#books_path = './texts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_files = glob.glob(books_path + '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Books/it/EDITED Agosto, Moglie Mia Non Ti Conosco - Achille Campanile.txt',\n",
       " './Books/it/EDITED Don Giovanni in Sicilia - Vitaliano Brancati.txt',\n",
       " './Books/it/EDITED italo_svevo_una_vita.txt',\n",
       " './Books/it/EDITED La variante di Luneburg - paolo mauresing.txt',\n",
       " './Books/it/EDITED italo_svevo_senilita.txt',\n",
       " './Books/it/EDITED italo_svevo_la_coscienza_di_zeno.txt',\n",
       " './Books/it/EDITED Un borghese piccolo piccolo - Vincenzo Cerami.txt',\n",
       " './Books/it/EDITED Natalia Ginzburg - Lessico familiare.txt',\n",
       " './Books/it/EDITED Tempo di uccidere - Ennio Flaiano.txt',\n",
       " './Books/it/EDITED Il prete bello - Parise, Goffredo.txt',\n",
       " './Books/it/EDITED La luna e i falo - Cesare Pavese.txt',\n",
       " './Books/it/EDITED italo_calvino_il_barone_rampante.txt',\n",
       " './Books/it/EDITED italo_calvino_il_visconte_dimezzato.txt',\n",
       " './Books/it/EDITED Non ti muovere - Mazzantini Margaret.txt',\n",
       " './Books/it/EDITED Oceano mare - Alessandro Baricco.txt',\n",
       " './Books/it/EDITED Il deserto dei Tartari - Dino Buzzati.txt',\n",
       " './Books/it/EDITED Venuto al mondo - Mazzantini Margaret.txt',\n",
       " './Books/it/EDITED carlo_cassola_la_ragazza_di_bube.txt',\n",
       " './Books/it/EDITED La Califfa - Alberto Bevilacqua.txt',\n",
       " './Books/it/EDITED Atlante occidentale - Daniele Del Giudice.txt',\n",
       " './Books/it/EDITED Verderame - Michele Mari.txt',\n",
       " './Books/it/EDITED alberto_moravia_la_noia.txt',\n",
       " './Books/it/EDITED domenico_starnone_via_gemito.txt',\n",
       " './Books/it/EDITED Se la luna mi porta fortuna - Achille Campanile.txt',\n",
       " './Books/it/EDITED Inseparabili (2012) - Alessandro Piperno.txt',\n",
       " './Books/it/EDITED beppe_fenoglio_una_questione_privata.txt',\n",
       " './Books/it/EDITED Il conformista - Alberto Moravia.txt',\n",
       " \"./Books/it/EDITED L'importanza dei luoghi comuni - Marcello Fois.txt\",\n",
       " './Books/it/EDITED elena_ferrante_l_amica_geniale.txt',\n",
       " './Books/it/EDITED umberto_eco_baudolino.txt',\n",
       " './Books/it/EDITED giorgio_bassani_il_giardino_dei_finzi_contini.txt',\n",
       " './Books/it/EDITED Canale Mussolini - Antonio Pennacchi.txt',\n",
       " './Books/it/EDITED Niente di personale - Roberto Cotroneo.txt',\n",
       " './Books/it/EDITED Ragionevoli dubbi - Gianrico Carofiglio.txt',\n",
       " './Books/it/EDITED Fai bei sogni - Massimo Gramellini.txt',\n",
       " './Books/it/EDITED Luce perfetta - Marcello Fois.txt',\n",
       " './Books/it/EDITED italo_calvino_il_sentiero_dei_nidi_di_ragno.txt',\n",
       " './Books/it/EDITED La solitudine dei numeri primi - Paolo Giordano.txt',\n",
       " './Books/it/EDITED italo_calvino_il_cavaliere_inesistente.txt',\n",
       " './Books/it/EDITED La scuola cattolica - Edoardo Albinati.txt',\n",
       " './Books/it/EDITED Divorziare con stile - Diego De Silva.txt',\n",
       " './Books/it/EDITED Il guardiano dei Sogni - Paolo Maurensing.txt',\n",
       " './Books/it/EDITED La Stanza del Vescovo - Piero Chiara.txt',\n",
       " './Books/it/EDITED Un eroe del nostro tempo.txt',\n",
       " './Books/it/EDITED Mammut - Antonio Pennacchi.txt',\n",
       " './Books/it/EDITED Il ragazzo morto e le comete (Biblioteca A - Parise, Goffredo.txt',\n",
       " \"./Books/it/EDITED L'uomo che guarda - Alberto Moravia.txt\",\n",
       " './Books/it/EDITED umberto_eco_l_isola_del_giorno_prima.txt',\n",
       " './Books/it/EDITED I volatili del Beato Angelico - Antonio Tabucchi.txt',\n",
       " './Books/it/EDITED Il suggeritore - Donato Carrisi.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = []\n",
    "for bf in book_files:\n",
    "    with open(bf, 'r') as f:\n",
    "        books.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpy():\n",
    "\n",
    "    def __init__(self, books, **kwargs):\n",
    "        self.mode                = kwargs.get('mode',                'word'  )\n",
    "        self.lower               = kwargs.get('lower',               True    )\n",
    "        self.one_document        = kwargs.get('one_document',        False   )\n",
    "        self.threshold           = kwargs.get('threshold',           None    )\n",
    "        self.threshold_section   = kwargs.get('threshold_section', 'first' ) # 'first', 'all' or int\n",
    "        self.text_sections       = kwargs.get('text_sections',       (1,)    ) # tuple or list: (train, valid, test, ...)\n",
    "        self.text_sections_level = kwargs.get('text_sections_level', 'book'  ) # 'book' or 'item'\n",
    "        self.init_books_seq      = kwargs.get('init_books_seq',      'normal') # 'normal', 'random' or sequence list\n",
    "        self.punct               = kwargs.get('punct',                \"'.,!?«»:;()[]-\"   ) # list or string of punctuation to divide words\n",
    "        \n",
    "        \n",
    "        self.ind_books = np.arange(len(books))\n",
    "        if type(self.init_books_seq) == str:\n",
    "            if self.init_books_seq == 'normal':\n",
    "                pass\n",
    "            elif self.init_books_seq == 'random':\n",
    "                np.random.shuffle(self.ind_books)\n",
    "            else:\n",
    "                warnings.warn('Init_books_seq not recognised. Using \\'normal\\'', UserWarning)\n",
    "        elif type(self.init_books_seq) == list:\n",
    "            self.ind_books = self.init_books_seq\n",
    "        else:\n",
    "            raise ValueError('init_books_seq must be a string (\\'normal\\' or \\'random\\') or a list of indexes')\n",
    "            \n",
    "                \n",
    "        if self.one_document:\n",
    "            string = ''\n",
    "            for b in books:\n",
    "                string += b + ' '\n",
    "            self.books = [string]\n",
    "            self.ind_books = [0]\n",
    "        else:\n",
    "            self.books = copy.deepcopy(books) # list of book strings\n",
    "        self.num_books = len(self.books)\n",
    "        \n",
    "        self.books_list_of_items = None # list of book lists containing the single items\n",
    "        self.books_encoding = None # list of book encodings\n",
    "        self.items_count = None # dictionary with the number of items (word or char) occourrences\n",
    "        self.items_freq = None # dictionary with the frequency of items occourrences\n",
    "        self.ind2item = None # dictionary to translate one item encoding to item\n",
    "        self.item2ind = None # dictionary to translate an item to the associated encoding\n",
    "        self.num_items = None # number of different items\n",
    "        \n",
    "        self.book_ind  = [0] * len(self.text_sections)\n",
    "        self.chunk_ind = [0] * len(self.text_sections)\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "    def _build(self):\n",
    "        all_items = []\n",
    "        self.books_list_of_items = []\n",
    "        \n",
    "        # Reading the full text\n",
    "        for k in self.ind_books:\n",
    "            b = self.books[k]\n",
    "            if self.lower:\n",
    "                self.books[k] = self.books[k].lower()\n",
    "            if self.mode == 'word':\n",
    "                for p in self.punct:\n",
    "                    self.books[k] = self.books[k].replace(p, \" \"+p+\" \")\n",
    "                while self.books[k].find('  ') > -1:\n",
    "                    self.books[k] = self.books[k].replace('  ', ' ')\n",
    "                self.books[k] = self.books[k].strip()\n",
    "                self.books_list_of_items.append(self.books[k].split(' '))\n",
    "            elif self.mode == 'char':\n",
    "                self.books_list_of_items.append(list(self.books[k]))\n",
    "            #all_items += self.books_list_of_items[-1]\n",
    "        \n",
    "        # Building the sections\n",
    "        self._sections_building()\n",
    "        \n",
    "        # Calculating the items distribution\n",
    "        if type(self.threshold_section) == int:\n",
    "            for kb, b in enumerate(self.sections_book[self.threshold_section]):\n",
    "                #print(b)\n",
    "                fr, to = self.sections_text[self.threshold_section][kb]\n",
    "                all_items += self.books_list_of_items[b][fr:to]\n",
    "        elif type(self.threshold_section) == str:\n",
    "            if self.threshold_section == 'first':\n",
    "                for kb, b in enumerate(self.sections_book[0]):\n",
    "                    fr, to = self.sections_text[0][b]\n",
    "                    all_items += self.books_list_of_items[kb][fr:to]\n",
    "            elif self.threshold_section == 'all':\n",
    "                for b in self.books_list_of_items:\n",
    "                    all_items += b\n",
    "                \n",
    "        self.items_count = collections.Counter(all_items)\n",
    "        self.items_count = {k: v for k, v in sorted(self.items_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "        self.num_items = len(self.items_count)\n",
    "        tot_items = len(all_items)\n",
    "        self.items_freq = dict()\n",
    "        for k in self.items_count:\n",
    "            self.items_freq[k] = self.items_count[k] / tot_items\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Cutting the distribution\n",
    "        if self.threshold is not None:\n",
    "            if self.mode == 'char':\n",
    "                warnings.warn('Char mode. Threshold should not be used.', UserWarning)\n",
    "            key2remove = []\n",
    "            if self.threshold > 1:\n",
    "                self.threshold = int(self.threshold)\n",
    "                for k, (key, value) in enumerate(self.items_count.items()):\n",
    "                    if k >= self.threshold:\n",
    "                        key2remove.append(key)\n",
    "            elif self.threshold < 1. and self.threshold > 0.:\n",
    "                cumv = 0.0\n",
    "                for key, value in self.items_freq.items():\n",
    "                    cumv += value\n",
    "                    if cumv >= self.threshold:\n",
    "                        key2remove.append(key)\n",
    "            else:\n",
    "                raise ValueError('max_items must be positive!')\n",
    "            for key in key2remove:\n",
    "                del self.items_freq[key]\n",
    "                del self.items_count[key]\n",
    "            self.num_items = len(self.items_count)\n",
    "        \n",
    "        # Building the dictionaries for connecting items to code\n",
    "        self.ind2item = dict()\n",
    "        self.item2ind = dict()\n",
    "        for k, key in enumerate(self.items_count):\n",
    "            self.ind2item[k] = key\n",
    "            self.item2ind[key] = k\n",
    "        self.item2ind = collections.OrderedDict(sorted(self.item2ind.items()))\n",
    "        \n",
    "        # Updating the text after cutting distribution\n",
    "        self.books_encoding = []\n",
    "        for kb, b in enumerate(self.books_list_of_items):\n",
    "            self.books_encoding.append([])\n",
    "            for k, w in enumerate(b):\n",
    "                code = self.item2ind.get(w, None)\n",
    "                self.books_encoding[-1].append(code)\n",
    "                self.books_list_of_items[kb][k] = self.ind2item.get(code)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Removing the unnecessary data\n",
    "        del self.books\n",
    "        del self.num_items\n",
    "        del self.items_count\n",
    "        del self.items_freq\n",
    "    \n",
    "    def _sections_building(self):\n",
    "        ss_sum = 0.0\n",
    "        self.text_sections = list(self.text_sections)\n",
    "        for ss in self.text_sections:\n",
    "            ss_sum += ss\n",
    "        for k, ss in enumerate(self.text_sections):\n",
    "            self.text_sections[k] /= ss_sum\n",
    "        full_text_len = 0\n",
    "        for kb in range(len(self.books_list_of_items)):\n",
    "            full_text_len += len(self.books_list_of_items[kb])\n",
    "        number_of_items_per_section = []\n",
    "        for section_k, ts in enumerate(self.text_sections):\n",
    "            number_of_items_per_section.append(int(ts * full_text_len))\n",
    "        if sum(number_of_items_per_section) < full_text_len:\n",
    "            number_of_items_per_section[-1] += full_text_len - sum(number_of_items_per_section)\n",
    "        \n",
    "        self.sections_book = [[]]\n",
    "        self.sections_text = [[]]\n",
    "        \n",
    "        if self.text_sections_level == 'item':\n",
    "            book = 0\n",
    "            fr = 0\n",
    "\n",
    "            for section_k, nips in enumerate(number_of_items_per_section):\n",
    "                nips_rem = number_of_items_per_section[section_k]\n",
    "                while nips_rem > 0:\n",
    "                    if len(self.books_list_of_items[book][fr:]) <= nips_rem:\n",
    "                        self.sections_book[section_k].append(book)\n",
    "                        self.sections_text[section_k].append([fr,len(self.books_list_of_items[book])])\n",
    "                        nips_rem -= len(self.books_list_of_items[book]) - fr\n",
    "                        fr = 0\n",
    "                        book += 1\n",
    "                    else:\n",
    "                        self.sections_book[section_k].append(book)\n",
    "                        if nips_rem > len(self.books_list_of_items[book]) - fr:\n",
    "                            to = len(self.books_list_of_items[book])\n",
    "                            self.sections_text[section_k].append([fr, to])\n",
    "                            fr = 0\n",
    "                            book += 1\n",
    "                            nips_rem -= to - fr\n",
    "                        else:\n",
    "                            to = fr + nips_rem\n",
    "                            self.sections_text[section_k].append([fr, to])\n",
    "                            nips_rem -= to - fr\n",
    "                            fr = to                        \n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                        \n",
    "        elif self.text_sections_level == 'book':\n",
    "            section_k = 0\n",
    "            temp_len = 0\n",
    "            for kb, b in enumerate(self.books_list_of_items):\n",
    "                if len(b) + temp_len < number_of_items_per_section[section_k]:\n",
    "                    self.sections_book[section_k].append(kb)\n",
    "                    self.sections_text[section_k].append([0, len(b)])\n",
    "                    temp_len += len(b)\n",
    "                else:\n",
    "                    if (number_of_items_per_section[section_k] - temp_len) > int(len(b) * 0.75):\n",
    "                        self.sections_book[section_k].append(kb)\n",
    "                        self.sections_text[section_k].append([0, len(b)])\n",
    "                        section_k += 1\n",
    "                        temp_len = 0\n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                    else:\n",
    "                        if len(self.sections_book) < len(self.text_sections):\n",
    "                            self.sections_book.append([])\n",
    "                            self.sections_text.append([])\n",
    "                            section_k += 1\n",
    "                            self.sections_book[section_k].append(kb)\n",
    "                            self.sections_text[section_k].append([0, len(b)])\n",
    "                            temp_len = len(b)\n",
    "            \n",
    "            for k, sb in enumerate(self.sections_book):\n",
    "                if sb == []:\n",
    "                    del self.sections_book[k]\n",
    "                    del self.sections_text[k]\n",
    "            \n",
    "            if len(self.sections_book) < len(self.text_sections):\n",
    "                wstr = 'Number of sections lower than requested: {}/{}'.format(len(self.sections_book), len(self.text_sections))\n",
    "                warnings.warn(wstr, UserWarning)\n",
    "        \n",
    "    \n",
    "    def reset_counter(self, section='all'):\n",
    "        if type(section) == int:\n",
    "            self.book_ind[section] = 0\n",
    "            self.chunk_ind[section] = 0\n",
    "        elif type(section) == str and section == 'all':\n",
    "            for s in range(len(self.sections_book)):\n",
    "                self.book_ind[s] = 0\n",
    "                self.chunk_ind[s] = 0\n",
    "    \n",
    "    def string2code(self, string):\n",
    "        code = []\n",
    "        string_list_of_items = []\n",
    "        if self.mode == 'word':\n",
    "            #self.punct = \"'.,!?«»:;()[]-\"\n",
    "            for p in self.punct:\n",
    "                string = string.replace(p, \" \"+p+\" \")\n",
    "            while string.find('  ') > -1:\n",
    "                string = string.replace('  ', ' ')\n",
    "            string = string.strip()\n",
    "            string_list_of_items = string.split(' ')\n",
    "        elif self.mode == 'char':\n",
    "            string_list_of_items = list(string)\n",
    "        for w in string_list_of_items:\n",
    "            code.append(self.item2ind.get(w))\n",
    "        return code\n",
    "    \n",
    "    def items2code(self, items):\n",
    "        code = []\n",
    "        for w in items:\n",
    "            code.append(self.item2ind.get(w))\n",
    "        return code\n",
    "    \n",
    "    def code2items(self, code):\n",
    "        items = []\n",
    "        for c in code:\n",
    "            items.append(self.ind2item.get(c))\n",
    "        return items\n",
    "    \n",
    "    def code2string(self, code):\n",
    "        string = ''\n",
    "        for c in code:\n",
    "            string += self.ind2item.get(c, 'UNK')\n",
    "            if self.mode == 'word':\n",
    "                string += ' '\n",
    "        string = string.strip()\n",
    "        return string\n",
    "    \n",
    "    def get_chunk(self, **kwargs):\n",
    "        book_sel     = kwargs.get('book_sel'      , -1        ) # book index relative to the chosen section\n",
    "        chunk_sel    = kwargs.get('chunk_sel'     , -1        ) # chunk starting index relative to the book in the section\n",
    "        chunk_len    = kwargs.get('chunk_len'     , 30        )\n",
    "        chunk_mode   = kwargs.get('chunk_mode'    , 'normal'  ) # 'normal', 'sequential', 'random'\n",
    "        padding      = kwargs.get('padding'       , 0         )\n",
    "        last_element = kwargs.get('last_element'  , True      )\n",
    "        output_mode  = kwargs.get('output_mode'   , 'code'    ) # 'code' list, 'item' list, 'string'\n",
    "        section      = kwargs.get('section'       , 0         ) # index (int) of the section or 'all'\n",
    "        unk          = kwargs.get('unk'           , 'max'     ) # In case of output_mode='code': \n",
    "                                                                #    'max': insert the code=max item\n",
    "                                                                #    'none': insert None\n",
    "                                                                # In case of output_mode='item' or 'string':\n",
    "                                                                #    insert the passed string\n",
    "        \n",
    "        if type(section) == int:\n",
    "            books = self.sections_book[section] # list of absolute index in the section\n",
    "        elif type(section) == str and section == 'all':\n",
    "            books = list(range(self.num_books))\n",
    "        texts = []\n",
    "        for kb, b in enumerate(books):\n",
    "            texts.append(self.sections_text[section][kb]) # list of couples [init,end] of each book in the section\n",
    "        num_books = len(books)        \n",
    "        \n",
    "        if chunk_mode == 'sequential':\n",
    "            book_sel_rel = self.book_ind[section]\n",
    "            book_sel_abs = books[book_sel_rel]\n",
    "            chunk_sel_abs = self.chunk_ind[section] + texts[book_sel_rel][0]\n",
    "        elif chunk_mode == 'random':\n",
    "            book_sel_rel = random.randint(0,len(books)-1)\n",
    "            book_sel_abs = books[book_sel_rel]\n",
    "            chunk_sel_abs = random.randint(texts[book_sel_rel][0], texts[book_sel_rel][1]-10)\n",
    "        elif chunk_mode == 'normal':\n",
    "            if book_sel == -1 or chunk_sel == -1:\n",
    "                raise ValueError('get_chunk: if sequential=False, book_sel and chunk_sel must be greater than -1')\n",
    "            else:\n",
    "                book_sel_rel = book_sel\n",
    "                book_sel_abs = books[book_sel_rel]\n",
    "                chunk_sel_abs = chunk_sel\n",
    "                if chunk_sel >= texts[book_sel_rel][1]:\n",
    "                    raise ValueError('get_chunk: chunk_sel is greater than the chosen section chunk')\n",
    "        \n",
    "        end_book = False\n",
    "    \n",
    "        if book_sel_abs < len(self.books_encoding):\n",
    "            if chunk_sel_abs < texts[book_sel_rel][1]:\n",
    "                fr = chunk_sel_abs\n",
    "                to = fr + chunk_len\n",
    "                if last_element:\n",
    "                    to += 1\n",
    "                if to > texts[book_sel_rel][1]:\n",
    "                    to = texts[book_sel_rel][1]\n",
    "                    end_book = True\n",
    "                if output_mode == 'code':\n",
    "                    output = self.books_encoding[book_sel_abs][fr:to]\n",
    "                    if unk == 'max':\n",
    "                        for k, o in enumerate(output):\n",
    "                            if o is None:\n",
    "                                output[k] = len(self.ind2item)\n",
    "                    elif unk == 'none':\n",
    "                        pass\n",
    "                elif output_mode == 'item':\n",
    "                    output = self.books_list_of_items[book_sel_abs][fr:to]\n",
    "                    for k, o in enumerate(output):\n",
    "                        if o is None:\n",
    "                            if self.mode == 'word':\n",
    "                                if unk=='max':\n",
    "                                    output[k] = 'UNK'\n",
    "                                elif unk=='none':\n",
    "                                    output[k] = None\n",
    "                                else:\n",
    "                                    output[k] = unk\n",
    "                elif output_mode == 'string':\n",
    "                    output = self.code2string(self.books_encoding[book_sel_abs][fr:to])\n",
    "            else:\n",
    "                raise ValueError('get_chunk: chunk_sel greater than book length')\n",
    "        else:\n",
    "            raise ValueError('get_chunk: book_sel greater than total books')\n",
    "            \n",
    "        if chunk_mode == 'sequential':\n",
    "            if end_book:\n",
    "                self.book_ind[section] += 1\n",
    "                if self.book_ind[section] >= len(books):\n",
    "                    self.book_ind[section] = 0\n",
    "                self.chunk_ind[section] = 0\n",
    "            else:\n",
    "                if padding < 1:\n",
    "                    self.chunk_ind[section] += chunk_len\n",
    "                else:\n",
    "                    self.chunk_ind[section] += padding\n",
    "                    if self.chunk_ind[section] >= len(texts[self.book_ind[section]]):\n",
    "                        self.chunk_ind[section] = 0\n",
    "                        self.book_ind[section] += 1\n",
    "                        if self.book_ind[section] >= len(books):\n",
    "                            self.book_ind[section] = 0\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    def save(self, namefile=''):\n",
    "        if namefile == '':\n",
    "            namefile = './corpy_'\n",
    "            ind = 0\n",
    "            while os.path.isfile(namefile + str(ind) + '.pkl'):\n",
    "                ind += 1\n",
    "            namefile += str(ind) + '.pkl'\n",
    "            print('Corpy file saved as: ' + namefile)\n",
    "        with open(namefile, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "            \n",
    "def load_corpy(namefile):\n",
    "    c = None\n",
    "    with open(namefile, 'rb') as f:\n",
    "        c = pickle.load(f)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-0a2cada8e25d>:230: UserWarning: Number of sections lower than requested: 1/3\n",
      "  warnings.warn(wstr, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpy(books, mode='word', text_sections=[80,15,5], text_sections_level='book', threshold_section=0, one_document=True)\n",
    "#len(corpus.ind2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpy file saved as: ./corpy_2.pkl\n"
     ]
    }
   ],
   "source": [
    "corpus.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = load_corpy('corpy_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[[[0, 5405745]]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus1.sections_book)\n",
    "print(corpus1.sections_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.reset_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['«',\n",
       "  'figliuolo',\n",
       "  '»',\n",
       "  '.',\n",
       "  '«',\n",
       "  'papà',\n",
       "  '»',\n",
       "  '.',\n",
       "  '«',\n",
       "  'questo',\n",
       "  'mi',\n",
       "  'pare',\n",
       "  'proprio',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'albergo',\n",
       "  'che',\n",
       "  'fa',\n",
       "  'per',\n",
       "  'noi',\n",
       "  '»',\n",
       "  '.',\n",
       "  '«',\n",
       "  'te',\n",
       "  'lo',\n",
       "  'stavo',\n",
       "  'per',\n",
       "  'dire',\n",
       "  '»',\n",
       "  '.',\n",
       "  '«'],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1.get_chunk(chunk_mode='sequential', section=0, output_mode='item'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_chunk(chunk_mode='normal', book_sel=1, chunk_sel=0, section=0, output_mode='string'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_chunk(chunk_mode='random', section=0, output_mode='string'), corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.book_ind[1] = 12\n",
    "corpus.chunk_ind[1] = 355000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.book_ind, corpus.chunk_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', text_sections=[0.8,0.4,0.1], text_sections_level='book', threshold_section='first')\n",
    "len(corpus.ind2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_chunk(chunk_mode='sequential', section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(corpus.sections_book[0])):\n",
    "    print(corpus.sections_book[0][k], corpus.sections_text[0][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', one_document=False)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', one_document=False, threshold=.99)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', threshold=.9, unk_coding='max')\n",
    "len(corpus.item2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = corpus.books_encoding[0]\n",
    "#corpus.code2items(code)\n",
    "#corpus.code2string(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='char', one_document=False, threshold=1000)\n",
    "len(corpus.items_count), len(corpus.items_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode: char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.reset_counter()\n",
    "chunk = corpus.get_chunk(chunk_mode='sequential',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='string',\n",
    "                         last_element=True,\n",
    "                         padding = 0)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='random',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='string',\n",
    "                         last_element=True)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode: word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(books, mode='word', threshold=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='sequential',\n",
    "                         chunk_len=30,\n",
    "                         #output_mode='item',\n",
    "                         output_mode='string',\n",
    "                         last_element=True,\n",
    "                         unk='none'\n",
    "                         )\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = corpus.get_chunk(chunk_mode='random',\n",
    "                         chunk_len=30,\n",
    "                         output_mode='item',\n",
    "                         last_element=True)\n",
    "len(chunk), chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casual phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = corpus.string2code('ci vediamo giovedì sera da Bernie')\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.code2items(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.code2string(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.items2code(['ci', 'vediamo', 'giovedì', 'sera', 'da', 'Bernie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
